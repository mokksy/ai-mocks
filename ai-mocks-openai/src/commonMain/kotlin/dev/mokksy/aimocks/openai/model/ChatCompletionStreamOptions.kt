/**
 *
 * Please note:
 * This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * Do not edit this file manually.
 *
 */

@file:Suppress(
    "ArrayInDataClass",
    "EnumEntryName",
    "RemoveRedundantQualifierName",
    "UnusedImport",
)

package dev.mokksy.aimocks.openai.model

import kotlinx.serialization.SerialName
import kotlinx.serialization.Serializable

/**
 * Options for streaming response. Only set this when you set `stream: true`.
 *
 * @param includeUsage If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array.   All other chunks will also include a `usage` field, but with a null value. **NOTE:** If the stream is interrupted, you may not receive the final usage chunk which contains the total token usage for the request.
 * @see <a href="https://platform.openai.com/docs/api-reference/chat/create#chat-create-stream_options">Stream Options</a>
 */
@Serializable
public data class ChatCompletionStreamOptions(
    // If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array.   All other chunks will also include a `usage` field, but with a null value. **NOTE:** If the stream is interrupted, you may not receive the final usage chunk which contains the total token usage for the request.
    @SerialName(value = "include_usage") val includeUsage: kotlin.Boolean? = null,
)
